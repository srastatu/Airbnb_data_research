{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are loading two datasets: 'listings.csv' and 'calendar.csv'. \n",
    "\n",
    "The 'listings.csv' file contains detailed information about various listings, while the 'calendar.csv' file contains pricing and availability information for each listing. \n",
    "Unfortunate price for all the different date here is the same so it will not allow us to provide analysis from this perspectives\n",
    "\n",
    "We then clean the 'price' columns in both datasets by removing dollar signs and commas, and converting the values to float type for easier numerical operations. \n",
    "Next, we calculate the average price for available listings and all listings, grouping by 'listing_id'. This helps us understand the pricing trends for available and all listings separately. \n",
    "\n",
    "Finally, we delete the 'price_df' to free up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\A93074843\\AppData\\Local\\Temp\\ipykernel_13152\\1063296803.py:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  listing_df['price'] = listing_df['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
      "C:\\Users\\A93074843\\AppData\\Local\\Temp\\ipykernel_13152\\1063296803.py:6: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  price_df['price'] = price_df['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n"
     ]
    }
   ],
   "source": [
    "listing_df = pd.read_csv('data/listings.csv')\n",
    "price_df = pd.read_csv('data/calendar.csv')\n",
    "\n",
    "#removing dollar signs and commas, and converting the values to float for both dataframes\n",
    "listing_df['price'] = listing_df['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "price_df['price'] = price_df['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "# this step is not necessary for our data, but it is a good practice to get mean  for availble prices\n",
    "# and mean for all prices \n",
    "grouped_avail_price_df = price_df[price_df['available'] == 't'].groupby('listing_id')['price'].mean().reset_index()\n",
    "grouped_avail_price_df.rename(columns={'price': 'average_price','listing_id': 'id'}, inplace=True)\n",
    "\n",
    "grouped_all_price_df = price_df.groupby('listing_id')['price'].mean().reset_index()\n",
    "grouped_all_price_df.rename(columns={'price': 'average_price','listing_id': 'id'}, inplace=True)\n",
    "\n",
    "del price_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrames and Handling Missing Values\n",
    "\n",
    "In this step, we merge the `listing_df` DataFrame with the `grouped_avail_price_df` and `grouped_all_price_df` DataFrames to incorporate the average prices for available and all listings, respectively. \n",
    "\n",
    "We then handle missing values in the `price` column by filling them with the corresponding average prices. This ensures that all listings have a price value, which is crucial for further analysis. \n",
    "\n",
    "Finally, we drop the `average_price` column from the merged DataFrames as it is no longer needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows before merge 7281\n",
      "number of missed price: 2554\n",
      " Number of rows after merge 7281\n",
      "number of missed price: 2147\n",
      " Number of rows after merge 7281\n",
      "number of missed price: 0\n"
     ]
    }
   ],
   "source": [
    "# try to merge prices to the listing_df where it's missing\n",
    "# results how much prices we have before and after merge are going to be printed\n",
    "print (f' Number of rows before merge {listing_df.shape[0]}')\n",
    "print (f'number of missed price: {listing_df['price'].isnull().sum()}')\n",
    "avail_merged_df = pd.merge(listing_df, grouped_avail_price_df, on='id', how='left')\n",
    "avail_merged_df['price'] = avail_merged_df['price'].fillna(avail_merged_df['average_price'])\n",
    "avail_merged_df.drop(columns=['average_price'], inplace=True)\n",
    "print (f' Number of rows after merge {avail_merged_df.shape[0]}')\n",
    "print (f'number of missed price: {avail_merged_df['price'].isnull().sum()}')\n",
    "\n",
    "\n",
    "all_merged_df = pd.merge(listing_df, grouped_all_price_df, on='id', how='left')\n",
    "all_merged_df['price'] = all_merged_df['price'].fillna(all_merged_df['average_price'])\n",
    "all_merged_df.drop(columns=['average_price'], inplace=True)\n",
    "print (f' Number of rows after merge {all_merged_df.shape[0]}')\n",
    "print (f'number of missed price: {all_merged_df['price'].isnull().sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Grouping Data\n",
    "\n",
    "In this step, we create a new column `accommodates_grouped` in both `avail_merged_df` and `all_merged_df` DataFrames to group listings that accommodate 6 or more people into a single category labeled '6+'. \n",
    "\n",
    "We also remove outliers by filtering out listings with a price greater than 1000 for one night. This helps in focusing the analysis on more typical listings and avoiding skewed results due to extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that groups accommodates values of 5 and more into a single category\n",
    "avail_merged_df['accommodates_grouped'] = avail_merged_df['accommodates'].apply(lambda x: '6+' if x >= 6 else str(x))\n",
    "all_merged_df['accommodates_grouped'] = all_merged_df['accommodates'].apply(lambda x: '6+' if x >= 6 else str(x))\n",
    "\n",
    "#Remove outliers we don't want to consider (price > 1000 for one night)\n",
    "avail_merged_df = avail_merged_df[all_merged_df['price'] <= 1000]\n",
    "all_merged_df = all_merged_df[all_merged_df['price'] <= 1000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haversine Function\n",
    "\n",
    "The Haversine function is used to calculate the great-circle distance between two points on the Earth's surface, given their latitude and longitude. This formula accounts for the spherical shape of the Earth and provides an accurate distance measurement.\n",
    "\n",
    "The function takes four parameters:\n",
    "- `lat1`: Latitude of the first point.\n",
    "- `lon1`: Longitude of the first point.\n",
    "- `lat2`: Latitude of the second point.\n",
    "- `lon2`: Longitude of the second point.\n",
    "\n",
    "The function returns the distance between the two points in kilometers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of the center of Munich\n",
    "munich_center = (48.137154, 11.576124)\n",
    "\n",
    "# Function to calculate the Haversine distance\n",
    "'''\n",
    "This function calculates the Haversine distance between two points on the Earth given their latitude and longitude in decimal degrees.\n",
    "Inputs:\n",
    "- lat1, lon1: latitude and longitude of point 1 in decimal degrees\n",
    "- lat2, lon2: latitude and longitude of point 2 in decimal degrees\n",
    "Output:\n",
    "- distance between the two points in kilometers\n",
    "Haversine formula:\n",
    "a = sin²(Δφ/2) + cos φ1 ⋅ cos φ2 ⋅ sin²(Δλ/2)\n",
    "c = 2 ⋅ atan2( √a, √(1−a) )\n",
    "\n",
    "'''\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of the Earth in km\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Distance from City Center\n",
    "\n",
    "In this step, we calculate the distance of each listing from the center of Munich using the Haversine formula. The Haversine formula is used to determine the distance between two points on the Earth's surface given their latitude and longitude. \n",
    "\n",
    "We then categorize these distances into different ranges: '0-3 km', '3-5 km', '5-10 km', and '10+ km'. This categorization helps in analyzing the distribution of listings based on their proximity to the city center. \n",
    "\n",
    "The calculated distances and their respective categories are added as new columns `distance_from_center` and `distance_category` in both `avail_merged_df` and `all_merged_df` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the listings into different distance ranges\n",
    "bins = [0, 3, 5, 10, np.inf]\n",
    "labels = ['0-3 km', '3-5 km', '5-10 km', '10+ km']\n",
    "\n",
    "# Calculate the distance of each listing from the center of Munich and categorize it\n",
    "avail_merged_df['distance_from_center'] = avail_merged_df.apply(lambda row: haversine(row['latitude'], row['longitude'], munich_center[0], munich_center[1]), axis=1)\n",
    "avail_merged_df['distance_category'] = pd.cut(avail_merged_df['distance_from_center'], bins=bins, labels=labels)\n",
    "\n",
    "all_merged_df['distance_from_center'] = all_merged_df.apply(lambda row: haversine(row['latitude'], row['longitude'], munich_center[0], munich_center[1]), axis=1)\n",
    "all_merged_df['distance_category'] = pd.cut(all_merged_df['distance_from_center'], bins=bins, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Processed DataFrames\n",
    "\n",
    "In the final step, we save the processed DataFrames `avail_merged_df` and `all_merged_df` to CSV files. These files can be used for further analysis or shared with others for their own analysis. The files are saved as `listings_avail_processed.csv` and `listings_all_processed.csv` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_merged_df.to_csv('data/listings_avail_processed.csv', index=False)\n",
    "all_merged_df.to_csv('data/listings_all_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
